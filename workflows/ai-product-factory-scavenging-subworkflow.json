{
  "name": "AI Product Factory - Context Scavenging",
  "nodes": [
    {
      "parameters": {
        "workflowInputs": {
          "values": [
            {
              "name": "project_id",
              "type": "string"
            },
            {
              "name": "session_id",
              "type": "string"
            },
            {
              "name": "drive_folder_id",
              "type": "string"
            },
            {
              "name": "uploaded_files",
              "type": "string"
            }
          ]
        }
      },
      "id": "subworkflow-entry",
      "name": "Subworkflow Entry Point",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [0, 0]
    },
    {
      "parameters": {
        "jsCode": "// Context Scavenging - State Initializer\n// Validates input and initializes scavenging state\n\nconst input = $input.first().json;\n\n// Validate required fields\nif (!input.project_id) {\n  throw new Error('Missing required field: project_id');\n}\n\nif (!input.session_id) {\n  throw new Error('Missing required field: session_id');\n}\n\nif (!input.drive_folder_id && !input.uploaded_files) {\n  throw new Error('Must provide either drive_folder_id or uploaded_files');\n}\n\n// Parse uploaded files if provided\nlet uploadedFiles = [];\nif (input.uploaded_files) {\n  if (typeof input.uploaded_files === 'string') {\n    try {\n      uploadedFiles = JSON.parse(input.uploaded_files);\n    } catch (e) {\n      uploadedFiles = [];\n    }\n  } else if (Array.isArray(input.uploaded_files)) {\n    uploadedFiles = input.uploaded_files;\n  }\n}\n\n// Generate unique scavenging session ID\nconst scavenging_id = 'scav_' + Date.now() + '_' + Math.random().toString(36).substring(2, 8);\n\nreturn {\n  json: {\n    project_id: input.project_id,\n    session_id: input.session_id,\n    scavenging_id,\n    drive_folder_id: input.drive_folder_id || null,\n    uploaded_files: uploadedFiles,\n    has_drive_folder: !!input.drive_folder_id,\n    has_uploaded_files: uploadedFiles.length > 0,\n    documents_processed: 0,\n    standards_found: [],\n    start_time: new Date().toISOString(),\n    status: 'initializing'\n  }\n};"
      },
      "id": "state-initializer",
      "name": "State Initializer",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [220, 0]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "has-drive-folder",
              "leftValue": "={{ $json.has_drive_folder }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        }
      },
      "id": "check-drive-folder",
      "name": "Has Drive Folder?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [440, 0]
    },
    {
      "parameters": {
        "resource": "fileFolder",
        "operation": "search",
        "queryString": "={{ \"'\" + $json.drive_folder_id + \"' in parents\" }}",
        "returnAll": true,
        "options": {}
      },
      "id": "list-drive-files",
      "name": "List Drive Files",
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [680, -100],
      "credentials": {
        "googleDriveOAuth2Api": {
          "id": "google-drive-oauth2",
          "name": "Google Drive OAuth2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Handle case with no drive folder - use only uploaded files\n\nconst state = $input.first().json;\n\nreturn {\n  json: {\n    ...state,\n    drive_files: [],\n    status: 'processing_uploads_only'\n  }\n};"
      },
      "id": "no-drive-folder",
      "name": "No Drive Folder Handler",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [680, 100]
    },
    {
      "parameters": {
        "jsCode": "// Filter and prepare documents for processing\n\nconst state = $('State Initializer').item.json;\nconst driveFiles = $input.all().map(item => item.json);\n\n// Filter for processable document types\nconst supportedMimeTypes = [\n  'application/pdf',\n  'application/vnd.google-apps.document',\n  'text/plain',\n  'text/markdown',\n  'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\n  'application/msword'\n];\n\nconst supportedExtensions = ['.md', '.txt', '.pdf', '.doc', '.docx'];\n\nconst processableFiles = driveFiles.filter(file => {\n  if (supportedMimeTypes.includes(file.mimeType)) return true;\n  const name = file.name || '';\n  return supportedExtensions.some(ext => name.toLowerCase().endsWith(ext));\n});\n\n// Combine with uploaded files\nconst allDocuments = [\n  ...processableFiles.map(f => ({\n    id: f.id,\n    name: f.name,\n    source: 'google_drive',\n    mimeType: f.mimeType\n  })),\n  ...state.uploaded_files.map((f, i) => ({\n    id: `upload_${i}`,\n    name: f.name || `uploaded_file_${i}`,\n    source: 'upload',\n    content: f.content || ''\n  }))\n];\n\nreturn {\n  json: {\n    ...state,\n    documents: allDocuments,\n    total_documents: allDocuments.length,\n    status: 'ready_for_processing'\n  }\n};"
      },
      "id": "prepare-documents",
      "name": "Prepare Documents",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [920, 0]
    },
    {
      "parameters": {
        "batchSize": 1,
        "options": {
          "reset": false
        }
      },
      "id": "batch-processor",
      "name": "Document Batch Processor",
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [1140, 0]
    },
    {
      "parameters": {
        "jsCode": "// Prepare document for Scavenger Agent\n// Extract content based on source type\n\nconst state = $('Prepare Documents').item.json;\nconst document = $input.first().json;\n\nlet documentContent = '';\n\nif (document.source === 'upload' && document.content) {\n  documentContent = document.content;\n} else {\n  // For Google Drive files, we need to download\n  // This will be handled by the conditional node\n  documentContent = '<<NEEDS_DOWNLOAD>>';\n}\n\nreturn {\n  json: {\n    ...state,\n    current_document: document,\n    document_content: documentContent,\n    needs_download: documentContent === '<<NEEDS_DOWNLOAD>>'\n  }\n};"
      },
      "id": "prepare-single-doc",
      "name": "Prepare Single Document",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1360, 0]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "needs-download",
              "leftValue": "={{ $json.needs_download }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        }
      },
      "id": "check-download",
      "name": "Needs Download?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [1580, 0]
    },
    {
      "parameters": {
        "resource": "file",
        "operation": "download",
        "fileId": {
          "__rl": true,
          "mode": "id",
          "value": "={{ $json.current_document.id }}"
        },
        "options": {
          "googleFileConversion": {
            "conversion": {
              "docsToFormat": "text/plain"
            }
          }
        }
      },
      "id": "download-document",
      "name": "Download Document",
      "type": "n8n-nodes-base.googleDrive",
      "typeVersion": 3,
      "position": [1820, -100],
      "credentials": {
        "googleDriveOAuth2Api": {
          "id": "google-drive-oauth2",
          "name": "Google Drive OAuth2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Extract text content from downloaded file\n\nconst prevState = $('Prepare Single Document').item.json;\nconst downloadedFile = $input.first();\n\nlet textContent = '';\n\n// Extract text from binary data\nif (downloadedFile.binary && downloadedFile.binary.data) {\n  textContent = Buffer.from(downloadedFile.binary.data.data, 'base64').toString('utf8');\n} else if (downloadedFile.json && downloadedFile.json.content) {\n  textContent = downloadedFile.json.content;\n}\n\n// Limit content length to prevent token overflow\nconst maxLength = 15000;\nif (textContent.length > maxLength) {\n  textContent = textContent.substring(0, maxLength) + '\\n\\n[Content truncated...]';\n}\n\nreturn {\n  json: {\n    ...prevState,\n    document_content: textContent,\n    content_length: textContent.length,\n    needs_download: false\n  }\n};"
      },
      "id": "extract-content",
      "name": "Extract Text Content",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2040, -100]
    },
    {
      "parameters": {
        "jsCode": "// Store current document state in static data before passing to Scavenger Agent\n// This allows the Parse Extracted Standards node to access the document info\n\nconst inputData = $input.first().json;\n\n// Store in static data for later retrieval\nconst staticData = $getWorkflowStaticData('global');\nstaticData.currentDocumentState = {\n  project_id: inputData.project_id,\n  session_id: inputData.session_id,\n  scavenging_id: inputData.scavenging_id,\n  current_document: inputData.current_document,\n  document_content: inputData.document_content\n};\n\n// Pass through the data\nreturn {\n  json: inputData\n};"
      },
      "id": "merge-content",
      "name": "Merge Content",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2260, 0]
    },
    {
      "parameters": {
        "options": {
          "systemMessage": "## Context\nYou are the Technical Scavenger - a meticulous analyst who extracts technical decisions and constraints from documentation with forensic precision.\n\n## Objective\nExtract ALL technical standards, patterns, decisions, and constraints from the provided document. Focus on:\n- Technology choices (databases, frameworks, languages, libraries)\n- Architecture patterns (microservices, event-driven, monolith, serverless)\n- Security requirements (authentication methods, encryption standards)\n- Integration constraints (APIs, protocols, data formats)\n- Compliance requirements (GDPR, SOC2, HIPAA, PCI-DSS)\n- Infrastructure decisions (cloud providers, hosting, containerization)\n- Development practices (testing strategies, CI/CD, coding standards)\n\n## Style\nOutput as a structured JSON array. Be thorough but avoid hallucination.\nIf uncertain about something, mark confidence as low.\nOnly extract what is explicitly stated or strongly implied.\n\n## Tone\nProfessional, analytical, precise.\n\n## Audience\nTechnical architects and decision-makers.\n\n## Response Format\nYou MUST respond with ONLY a valid JSON array. No explanation, no markdown, just the JSON:\n```json\n[\n  {\n    \"name\": \"Technology/Pattern Name\",\n    \"type\": \"technology|pattern|standard|requirement|constraint\",\n    \"description\": \"Detailed description of what this entails\",\n    \"source\": \"Document name or section where found\",\n    \"confidence\": 0.0-1.0,\n    \"category\": \"database|framework|language|security|infrastructure|integration|compliance|development\"\n  }\n]\n```\n\nIf no technical standards are found, return an empty array: []"
        },
        "text": "=Document: {{ $json.current_document.name }}\n\n---\n\n{{ $json.document_content }}\n\n---\n\nExtract all technical standards, patterns, and constraints from this document. Return ONLY a JSON array."
      },
      "id": "scavenger-agent",
      "name": "Scavenger Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.7,
      "position": [2500, 0]
    },
    {
      "parameters": {
        "model": "={{ $env.MODEL_CONTEXT || 'google/gemini-1.5-pro' }}",
        "options": {
          "temperature": 0.2,
          "maxTokens": 4096
        }
      },
      "id": "scavenger-model",
      "name": "Claude 3.5 Sonnet",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [2500, 220],
      "credentials": {
        "openRouterApi": {
          "id": "openrouter-api",
          "name": "OpenRouter API"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Parse Scavenger Agent response and extract standards\n// Accumulate standards across all document iterations using static data\n\n// Get state from the Scavenger Agent's input (which came from Merge Content)\nconst agentResponse = $input.first().json;\nconst responseText = agentResponse.output || agentResponse.text || '';\n\n// Get the previous state from static data or try to access from execution context\nconst staticData = $getWorkflowStaticData('global');\n\n// Retrieve the current document state that was stored before calling the agent\nconst prevState = staticData.currentDocumentState || {};\n\n// Try to parse JSON from response\nlet extractedStandards = [];\ntry {\n  // Try direct parse\n  extractedStandards = JSON.parse(responseText);\n} catch (e) {\n  // Try to extract JSON from markdown code block\n  const jsonMatch = responseText.match(/```(?:json)?\\s*([\\s\\S]*?)```/);\n  if (jsonMatch) {\n    try {\n      extractedStandards = JSON.parse(jsonMatch[1].trim());\n    } catch (e2) {\n      // Try to find any JSON array in the response\n      const arrayMatch = responseText.match(/\\[\\s*\\{[\\s\\S]*\\}\\s*\\]/);\n      if (arrayMatch) {\n        try {\n          extractedStandards = JSON.parse(arrayMatch[0]);\n        } catch (e3) {\n          extractedStandards = [];\n        }\n      }\n    }\n  }\n}\n\n// Ensure it's an array\nif (!Array.isArray(extractedStandards)) {\n  extractedStandards = extractedStandards ? [extractedStandards] : [];\n}\n\n// Add document source to each standard\nconst currentDoc = prevState.current_document || { name: 'unknown', id: 'unknown' };\nconst standardsWithSource = extractedStandards.map(std => ({\n  ...std,\n  document_name: currentDoc.name,\n  document_id: currentDoc.id,\n  extracted_at: new Date().toISOString()\n}));\n\n// Accumulate standards in workflow static data\nif (!staticData.accumulatedStandards) {\n  staticData.accumulatedStandards = [];\n}\nstaticData.accumulatedStandards.push(...standardsWithSource);\nstaticData.lastProcessedState = {\n  project_id: prevState.project_id || 'unknown',\n  session_id: prevState.session_id || 'unknown',\n  scavenging_id: prevState.scavenging_id || 'unknown'\n};\n\nreturn {\n  json: {\n    project_id: prevState.project_id || 'unknown',\n    session_id: prevState.session_id || 'unknown',\n    scavenging_id: prevState.scavenging_id || 'unknown',\n    document_name: currentDoc.name,\n    standards_count: standardsWithSource.length,\n    standards: standardsWithSource,\n    accumulated_count: staticData.accumulatedStandards.length\n  }\n};"
      },
      "id": "parse-standards",
      "name": "Parse Extracted Standards",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2720, 0]
    },
    {
      "parameters": {
        "jsCode": "// Aggregate all extracted standards from static data\n// This node is triggered when batch processing is complete\n\nconst input = $input.first().json;\n\n// Read accumulated standards from workflow static data\nconst staticData = $getWorkflowStaticData('global');\nconst allStandards = staticData.accumulatedStandards || [];\nconst lastState = staticData.lastProcessedState || {};\n\n// CLEANUP: Clear static data to prevent state leakage between workflow runs\ndelete staticData.accumulatedStandards;\ndelete staticData.lastProcessedState;\ndelete staticData.currentDocumentState;\n\n// Deduplicate by name (keep highest confidence)\nconst standardsMap = new Map();\nallStandards.forEach(std => {\n  const key = (std.name || '').toLowerCase();\n  if (!standardsMap.has(key) || (std.confidence || 0) > (standardsMap.get(key).confidence || 0)) {\n    standardsMap.set(key, std);\n  }\n});\n\nconst uniqueStandards = Array.from(standardsMap.values());\n\n// Use state from last processed item or from input\nconst project_id = lastState.project_id || input.project_id || 'unknown';\nconst session_id = lastState.session_id || input.session_id || 'unknown';\nconst scavenging_id = lastState.scavenging_id || input.scavenging_id || 'unknown';\n\nreturn {\n  json: {\n    project_id,\n    session_id,\n    scavenging_id,\n    total_standards: uniqueStandards.length,\n    standards: uniqueStandards,\n    status: uniqueStandards.length > 0 ? 'standards_extracted' : 'no_standards_found'\n  }\n};"
      },
      "id": "aggregate-standards",
      "name": "Aggregate All Standards",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [2960, 0]
    },
    {
      "parameters": {
        "jsCode": "// Prepare standards for tech governance approval\n// Split into items for individual processing\n\nconst state = $input.first().json;\nconst standards = state.standards || [];\n\nif (standards.length === 0) {\n  return {\n    json: {\n      ...state,\n      has_standards: false,\n      message: 'No technical standards found in documents'\n    }\n  };\n}\n\n// Return each standard as a separate item for governance processing\nreturn standards.map((std, index) => ({\n  json: {\n    project_id: state.project_id,\n    session_id: state.session_id,\n    scavenging_id: state.scavenging_id,\n    standard_index: index,\n    total_standards: standards.length,\n    standard: std,\n    requires_approval: true\n  }\n}));"
      },
      "id": "split-for-governance",
      "name": "Split for Governance",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [3180, 0]
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "mode": "name",
          "value": "Titan - Graphiti Operations"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "operation": "search_facts",
            "query": "={{ 'technology standard ' + $json.standard.name }}",
            "group_ids": "[\"global_standards\"]"
          }
        }
      },
      "id": "check-existing-standard",
      "name": "Check Existing Standard",
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.2,
      "position": [3420, 0]
    },
    {
      "parameters": {
        "jsCode": "// Check if standard already exists and prepare governance decision\n\nconst prevData = $('Split for Governance').item.json;\nconst graphitiResult = $input.first().json;\n\n// Check if we found existing standards\nconst existingResults = graphitiResult.result || [];\nconst alreadyExists = existingResults.length > 0;\n\n// Determine if this needs user approval\nlet needsApproval = true;\nlet existingScope = null;\n\nif (alreadyExists) {\n  // Standard already in knowledge graph\n  needsApproval = false;\n  existingScope = 'global'; // If found in global_standards search\n}\n\nreturn {\n  json: {\n    ...prevData,\n    already_exists: alreadyExists,\n    existing_scope: existingScope,\n    needs_approval: needsApproval,\n    graphiti_results: existingResults\n  }\n};"
      },
      "id": "check-governance",
      "name": "Check Governance Status",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [3660, 0]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "needs-approval",
              "leftValue": "={{ $json.needs_approval }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        }
      },
      "id": "needs-approval-check",
      "name": "Needs User Approval?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [3880, 0]
    },
    {
      "parameters": {
        "jsCode": "// Prepare webhook confirmation request for user\n\nconst data = $input.first().json;\nconst std = data.standard;\n\n// Generate unique webhook suffix for this approval\nconst webhookSuffix = `tech_approval_${data.scavenging_id}_${data.standard_index}`;\n\nconst confirmationMessage = `I found a new technology standard:\n\n**${std.name}** (${std.type})\n- Category: ${std.category || 'general'}\n- Source: ${std.document_name}\n- Confidence: ${(std.confidence * 100).toFixed(0)}%\n- Description: ${std.description}\n\nIs this a **Global Standard** (applies across all projects) or **Local Standard** (this project only)?`;\n\nreturn {\n  json: {\n    ...data,\n    webhook_suffix: webhookSuffix,\n    confirmation_message: confirmationMessage,\n    awaiting_response: true\n  }\n};"
      },
      "id": "prepare-approval-request",
      "name": "Prepare Approval Request",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [4120, -100]
    },
    {
      "parameters": {
        "resume": "webhook",
        "options": {
          "webhookSuffix": "={{ $json.webhook_suffix }}"
        }
      },
      "id": "wait-for-approval",
      "name": "Wait for User Approval",
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1.1,
      "position": [4340, -100],
      "webhookId": "tech-governance-approval"
    },
    {
      "parameters": {
        "jsCode": "// Process user's approval response\n\nconst prevData = $('Prepare Approval Request').item.json;\nconst webhookData = $input.first().json;\n\n// Parse user response - expecting { \"scope\": \"global|local|skip\" }\nconst userDecision = webhookData.body?.scope || webhookData.scope || 'skip';\n\nlet approved = false;\nlet scope = null;\n\nif (userDecision === 'global') {\n  approved = true;\n  scope = 'global';\n} else if (userDecision === 'local') {\n  approved = true;\n  scope = 'local';\n}\n\nreturn {\n  json: {\n    ...prevData,\n    user_decision: userDecision,\n    approved,\n    scope,\n    response_timestamp: new Date().toISOString()\n  }\n};"
      },
      "id": "process-approval",
      "name": "Process Approval Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [4560, -100]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "approved",
              "leftValue": "={{ $json.approved }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        }
      },
      "id": "check-approved",
      "name": "Was Approved?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [4780, -100]
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "mode": "name",
          "value": "Titan - Graphiti Operations"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "operation": "add_episode",
            "name": "={{ 'Tech Standard: ' + $json.standard.name }}",
            "content": "={{ JSON.stringify($json.standard) }}",
            "source": "document",
            "source_description": "={{ 'Extracted from: ' + $json.standard.document_name }}",
            "group_id": "={{ $json.scope === 'global' ? 'global_standards' : $json.project_id }}"
          }
        }
      },
      "id": "store-in-graphiti",
      "name": "Store in Graphiti",
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.2,
      "position": [5020, -200]
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "mode": "name",
          "value": "Titan - Qdrant Operations"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "operation": "upsert",
            "content": "={{ $json.standard.name + ': ' + $json.standard.description }}",
            "scope": "={{ $json.scope }}",
            "type": "standard",
            "source": "={{ $json.standard.document_name }}",
            "metadata": "={{ JSON.stringify({ category: $json.standard.category, confidence: $json.standard.confidence, type: $json.standard.type }) }}"
          }
        }
      },
      "id": "store-in-qdrant",
      "name": "Store in Qdrant",
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.2,
      "position": [5020, 0]
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "mode": "name",
          "value": "AI Product Factory - Decision Logger"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {
            "operation": "log_decision",
            "project_id": "={{ $json.project_id }}",
            "session_id": "={{ $json.session_id }}",
            "phase": "0",
            "entry_type": "tech_standard_discovery",
            "content": "={{ $json.standard.name }}",
            "metadata": "={{ JSON.stringify({ name: $json.standard.name, type: $json.standard.type, source: $json.standard.document_name, confidence: $json.standard.confidence, user_decision: 'Approved as ' + $json.scope + ' Standard', stored_in: 'Graphiti (' + ($json.scope === 'global' ? 'global_standards' : $json.project_id) + '), Qdrant (scope: ' + $json.scope + ')' }) }}"
          }
        }
      },
      "id": "log-approval",
      "name": "Log Approval Decision",
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.2,
      "position": [5260, -100]
    },
    {
      "parameters": {
        "jsCode": "// Mark standard as skipped (not approved)\n\nconst data = $input.first().json;\n\nreturn {\n  json: {\n    ...data,\n    stored: false,\n    skip_reason: 'User declined to approve'\n  }\n};"
      },
      "id": "skip-standard",
      "name": "Skip Standard",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [5020, 200]
    },
    {
      "parameters": {
        "jsCode": "// Handle already existing standard\n\nconst data = $input.first().json;\n\nreturn {\n  json: {\n    ...data,\n    stored: false,\n    skip_reason: 'Already exists in knowledge graph',\n    existing_scope: data.existing_scope\n  }\n};"
      },
      "id": "already-exists",
      "name": "Already Exists Handler",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [4120, 100]
    },
    {
      "parameters": {
        "mode": "combine",
        "mergeByFields": {
          "values": []
        },
        "options": {}
      },
      "id": "merge-governance-results",
      "name": "Merge Governance Results",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [5500, 0]
    },
    {
      "parameters": {
        "jsCode": "// Aggregate final scavenging results\n\nconst allResults = $input.all();\n\n// Get first item for common data\nconst firstItem = allResults[0].json;\n\n// Count results\nlet approvedGlobal = 0;\nlet approvedLocal = 0;\nlet skipped = 0;\nlet alreadyExisted = 0;\n\nconst processedStandards = allResults.map(item => {\n  const data = item.json;\n  \n  if (data.stored === false) {\n    if (data.already_exists) {\n      alreadyExisted++;\n    } else {\n      skipped++;\n    }\n  } else if (data.scope === 'global') {\n    approvedGlobal++;\n  } else if (data.scope === 'local') {\n    approvedLocal++;\n  }\n  \n  return {\n    name: data.standard?.name,\n    type: data.standard?.type,\n    scope: data.scope || 'skipped',\n    stored: data.stored !== false\n  };\n});\n\nreturn {\n  json: {\n    project_id: firstItem.project_id,\n    session_id: firstItem.session_id,\n    scavenging_id: firstItem.scavenging_id,\n    phase: 0,\n    status: 'completed',\n    summary: {\n      total_standards_found: allResults.length,\n      approved_global: approvedGlobal,\n      approved_local: approvedLocal,\n      skipped: skipped,\n      already_existed: alreadyExisted\n    },\n    processed_standards: processedStandards,\n    completed_at: new Date().toISOString()\n  }\n};"
      },
      "id": "final-aggregation",
      "name": "Final Aggregation",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [5720, 0]
    },
    {
      "parameters": {
        "jsCode": "// Final Output - Return scavenging results to caller workflow\n// Ensures proper data structure for parent workflow consumption\n\nconst data = $input.first().json;\n\nreturn {\n  json: {\n    project_id: data.project_id,\n    session_id: data.session_id,\n    scavenging_id: data.scavenging_id,\n    phase: data.phase || 0,\n    status: data.status || 'completed',\n    summary: data.summary || {},\n    processed_standards: data.processed_standards || [],\n    completed_at: data.completed_at || new Date().toISOString()\n  }\n};"
      },
      "id": "output-node",
      "name": "Subworkflow Output",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [5940, 0]
    }
  ],
  "connections": {
    "Subworkflow Entry Point": {
      "main": [
        [
          {
            "node": "State Initializer",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "State Initializer": {
      "main": [
        [
          {
            "node": "Has Drive Folder?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Drive Folder?": {
      "main": [
        [
          {
            "node": "List Drive Files",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "No Drive Folder Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "List Drive Files": {
      "main": [
        [
          {
            "node": "Prepare Documents",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "No Drive Folder Handler": {
      "main": [
        [
          {
            "node": "Prepare Documents",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Documents": {
      "main": [
        [
          {
            "node": "Document Batch Processor",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Document Batch Processor": {
      "main": [
        [
          {
            "node": "Prepare Single Document",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Aggregate All Standards",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Single Document": {
      "main": [
        [
          {
            "node": "Needs Download?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Needs Download?": {
      "main": [
        [
          {
            "node": "Download Document",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Merge Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Download Document": {
      "main": [
        [
          {
            "node": "Extract Text Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Text Content": {
      "main": [
        [
          {
            "node": "Merge Content",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Content": {
      "main": [
        [
          {
            "node": "Scavenger Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude 3.5 Sonnet": {
      "ai_languageModel": [
        [
          {
            "node": "Scavenger Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Scavenger Agent": {
      "main": [
        [
          {
            "node": "Parse Extracted Standards",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Extracted Standards": {
      "main": [
        [
          {
            "node": "Document Batch Processor",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate All Standards": {
      "main": [
        [
          {
            "node": "Split for Governance",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split for Governance": {
      "main": [
        [
          {
            "node": "Check Existing Standard",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Existing Standard": {
      "main": [
        [
          {
            "node": "Check Governance Status",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Governance Status": {
      "main": [
        [
          {
            "node": "Needs User Approval?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Needs User Approval?": {
      "main": [
        [
          {
            "node": "Prepare Approval Request",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Already Exists Handler",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Approval Request": {
      "main": [
        [
          {
            "node": "Wait for User Approval",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Wait for User Approval": {
      "main": [
        [
          {
            "node": "Process Approval Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Process Approval Response": {
      "main": [
        [
          {
            "node": "Was Approved?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Was Approved?": {
      "main": [
        [
          {
            "node": "Store in Graphiti",
            "type": "main",
            "index": 0
          },
          {
            "node": "Store in Qdrant",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Skip Standard",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store in Graphiti": {
      "main": [
        [
          {
            "node": "Log Approval Decision",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store in Qdrant": {
      "main": [
        [
          {
            "node": "Log Approval Decision",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Log Approval Decision": {
      "main": [
        [
          {
            "node": "Merge Governance Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Skip Standard": {
      "main": [
        [
          {
            "node": "Merge Governance Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Already Exists Handler": {
      "main": [
        [
          {
            "node": "Merge Governance Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Governance Results": {
      "main": [
        [
          {
            "node": "Final Aggregation",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Final Aggregation": {
      "main": [
        [
          {
            "node": "Subworkflow Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "1",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "ai-product-factory"
  },
  "id": "ai-product-factory-scavenging",
  "tags": [
    {
      "id": "ai-product-factory",
      "name": "AI Product Factory"
    }
  ]
}
